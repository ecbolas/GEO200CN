---
title: "Lab6"
author: GEO200CN, spring 2017
output: html_document
---

# Lab 6: Point patterns

```{r, echo=FALSE, include=FALSE}
	library(knitr)
	opts_chunk$set(
		fig.width  = 5,
		fig.height = 5,
		collapse   = TRUE
	)
```

Please read oip

Download the data from the website.

Answer the numbered questions in a single *R Markdown* file + HTML.

```{r, fig.align='center'}
datapath <- "~/Desktop/GEO200CN"
library(raster)
city <- readRDS(file.path(datapath, "city.rds"))
crime <- readRDS(file.path(datapath,"crime.rds"))
plot(city, col='light blue')
points(crime, col='red', cex=.5, pch='+')
```
A sorted table of the incidence of crime types.
```{r}
tb <- sort(table(crime$CATEGORY))[-1]
##[-1] modifies this so it sorts the table but "leaves out" (-) the 1st CATEGORY
tb 
```
Get the coordinates of the crime data, and remove duplicate crime locations. These are the ‘events’ we will use below (later we’ll go back to the full data set).
```{r}
xy <- coordinates(crime)
dim(xy)
##now change xy so it only reflects unique locations
xy <- unique(xy)
dim(xy)
head(xy)
```
###5.2 - Basic Statistics
Compute the mean center and standard distance for the crime data (see page 125 of OSU).
```{r}
# mean center
mc <- apply(xy, 2, mean)
mc
# standard distance
sd <- sqrt(sum((xy[,1] - mc[1])^2 + (xy[,2] - mc[2])^2) / nrow(xy))
plot(city, col='light blue')
points(crime, cex=.5)
points(cbind(mc[1], mc[2]), pch='*', col='red', cex=5)
# make a circle
bearing <- 1:360 * pi/180
cx <- mc[1] + sd * cos(bearing)
cy <- mc[2] + sd * sin(bearing)
circle <- cbind(cx, cy)
lines(circle, col='red', lwd=2)
```
###5.3 Density
```{r}
##Here is a basic approach to computing point density.
city
CityArea <- area(city)
CityArea
nrow(xy)
dens <- nrow(xy) / CityArea
##units = usft
```
###Question 1a) What is the unit of ‘dens’?

number of points("events")/276744329sqft(total city area)
or
number of crime events/square foot


###Question 1b) What is the number of crimes per square km?
```{r}
denskm2 <- (nrow(xy)/CityArea)*(1/0.0000000929)
denskm2
```
Create quadrats (raster layer)
```{r }
r <- raster(city)
res(r) <- 1000
r
```
To find the cells that are in the city, and for easy display, I create polygons from the RasterLayer.
```{r}
r <- rasterize(city, r)
plot(r)
quads <- as(r, 'SpatialPolygons')
plot(quads, add=TRUE)
points(crime, col='red', cex=.5)
```
Summarize the number of points within each cell, but also to compute statistics based on the ‘marks’ (attributes). 
```{r}
nc <- rasterize(coordinates(crime), r, fun='count', background=0)
plot(nc)
plot(city, add=TRUE)
##nc has crime counts. As we only have data for the city, the areas outside of the city need to be excluded. We can do that with the mask function
ncrimes <- mask(nc, r)
plot(ncrimes)
plot(city, add=TRUE)
```
now the frequencies
```{r}
f <- freq(ncrimes, useNA='no')
head(f)
plot(f, pch=20)
```
Now compute average number of cases per quadrat.
```{r}
# number of quadrats
quadrats <- sum(f[,2])
# number of cases
cases <- sum(f[,1] * f[,2])
mu <- cases / quadrats
mu
```
Create a table
```{r}
ff <- data.frame(f)
colnames(ff) <- c('K', 'X')
ff$Kmu <- ff$K - mu
ff$Kmu2 <- ff$Kmu^2
ff$XKmu2 <- ff$Kmu2 * ff$X
head(ff)
#observed variance
s2 <- sum(ff$XKmu2) / (sum(ff$X)-1)
s2
#VMR score
VMR <- s2 / mu
VMR
```
###Question 2:What does this VMR score tell us about the point pattern?
 A VMR > 1 indicates that the points are overdispersed (i.e. clustered)
 ###5.3 Distance Based measures
 we can use the dist function to compute the distances between pairs of points. 
 
 
```{r}
d <- dist(xy)
class(d)
#coerce the dist object to a matrix, and ignore distances from each point to itself (the zeros on the diagonal).
dm <- as.matrix(d)
diag(dm) <- NA
dm[1:5, 1:5]
```
To get, for each point, the minimum distance to another event, we can use the ‘apply’ function. 
```{r}
dmin <- apply(dm, 1, min, na.rm=TRUE)
head(dmin)
mdmin <- mean(dmin)
#Which point is its nearest neighbour? Use the ‘which.min’ function
wdmin <- apply(dm, 1, which.min)
```
Shows a plot of the top 25 cases that are furthest away from their nearet neighbor
```{r}
plot(city)
points(crime, cex=.1)
ord <- rev(order(dmin))

far25 <- ord[1:25]
neighbors <- wdmin[far25]

points(xy[far25, ], col='blue', pch=20)
points(xy[neighbors, ], col='red')

# drawing the lines, easiest via a loop
for (i in far25) {
    lines(rbind(xy[i, ], xy[wdmin[i], ]), col='red')
}
```
Now on to the G function
```{r}
max(dmin)
# get the unique distances (for the x-axis)
distance <- sort(unique(round(dmin)))
# compute how many cases there with distances smaller that each x
Gd <- sapply(distance, function(x) sum(dmin < x))
# normalize to get values between 0 and 1
Gd <- Gd / length(dmin)
plot(distance, Gd)
# using xlim to exclude the extremes
plot(distance, Gd, xlim=c(0,500))
```
This is another way to show the same thing, but in a stepwise fashion
```{r}
stepplot <- function(x, y, type='l', add=FALSE, ...) {
    x <- as.vector(t(cbind(x, c(x[-1], x[length(x)]))))
    y <- as.vector(t(cbind(y, y)))
  if (add) {
     lines(x,y, ...)
  } else {
       plot(x,y, type=type, ...)
  }
}
stepplot(distance, Gd, type='l', lwd=2, xlim=c(0,500))
```
Compute the F function using the centers of our raster cells
```{r}
# get the centers of the 'quadrats' (raster cells)
p <- rasterToPoints(r)
# compute distance from all crime sites to these cell centers
d2 <- pointDistance(p[,1:2], xy, longlat=FALSE)

# the remainder is similar to the G function
Fdistance <- sort(unique(round(d2)))
mind <- apply(d2, 1, min)
Fd <- sapply(Fdistance, function(x) sum(mind < x))
Fd <- Fd / length(mind)
plot(Fdistance, Fd, type='l', lwd=2, xlim=c(0,3000))
#compute expected distribution
ef <- function(d, lambda) {
  E <- 1 - exp(-1 * lambda * pi * d^2)
}
expected <- ef(0:2000, dens)
#combine F and G on one plot
plot(distance, Gd, type='l', lwd=2, col='red', las=1,
    ylab='F(d) or G(d)', xlab='Distance', yaxs="i", xaxs="i")
lines(Fdistance, Fd, lwd=2, col='blue')
lines(0:2000, expected, lwd=2)

legend(1200, .3,
   c(expression(italic("G")["d"]), expression(italic("F")["d"]), 'expected'),
   lty=1, col=c('red', 'blue', 'black'), lwd=2, bty="n")
```
###Question 3: What does this plot suggest about the point pattern?


Finally, let’s compute K. Note that I use the original distance matrix ‘d’ here.
```{r}
distance <- seq(1, 30000, 100)
Kd <- sapply(distance, function(x) sum(d < x)) # takes a while
Kd <- Kd / (length(Kd) * dens)
plot(distance, Kd, type='l', lwd=2)
```

###Question 4: Create a single random pattern of events for the city, with the same number of events as the crime data (object xy). Use function ‘spsample’

###Question 5: Compute the G function, and plot it on a single plot, together with the G function for the observed crime data, and the theoretical expectation (formula 5.12).

###Question 6: (Difficult!) Do a Monte Carlo simulation (page 149) to see if the ‘mean nearest distance’ of the observed crime data is significantly different from a random pattern. Use a ‘for loop’. First write ‘pseudo-code’. That is, say in natural language what should happen. Then try to write R code that implements this.
